{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "TXzWGyz6_NWR",
        "outputId": "6316f5c2-f59e-42e4-d8b0-095cff6815db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéÅ Hello! I'm your personal assistant. Ask me anything! üéà\n",
            "You: Hello\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-4bed9bd500e1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-4bed9bd500e1>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mrecommend_gifts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mgeneral_chat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-4bed9bd500e1>\u001b[0m in \u001b[0;36mgeneral_chat\u001b[0;34m(user_message)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mshow_gif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         response = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_message\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    766\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             )\n",
            "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "import re\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# Set OpenAI API key\n",
        "openai.api_key = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
        "\n",
        "# Load gift data\n",
        "gift_df = pd.read_excel('/content/Cadeaux_Produits (version 1).xlsx')\n",
        "\n",
        "# Define the gift-related keywords\n",
        "gift_keywords = [\n",
        "    'gift', 'present', 'surprise'\n",
        "]\n",
        "\n",
        "# Define FAQ-related patterns with regex\n",
        "faq_patterns = [\n",
        "    (r\".*how.*recommend.*gift.*\", \"üéÅ I recommend gifts by asking you questions about the recipient, their interests, the occasion, and your budget. Then I match this info with my awesome gift database! ‚ú®\"),\n",
        "    (r\".*save.*preference.*\", \"üíæ I'm working on that! Right now, I can't save preferences, but that's a feature coming soon! Stay tuned! üòâ\"),\n",
        "    (r\".*how.*sure.*gift.*like.*\", \"ü§î I can't be 100% sure, but I match gifts to interests, age, and occasion to give you the best options! üéØ\"),\n",
        "    (r\".*more.*idea.*gift.*\", \"‚ú® Of course! Just let me know and I'll show you even more amazing gift ideas! üéâ\"),\n",
        "    (r\".*refine.*result.*\", \"üîç You can refine your search by giving me more details about the person, their hobbies, or adjusting your budget! üí°\")\n",
        "]\n",
        "\n",
        "# Fun emojis and GIF links for more engaging interactions\n",
        "fun_emojis = ['üéÅ', '‚ú®', 'ü•≥', 'üéâ', 'üéà', 'üíù', 'üõçÔ∏è', 'üéä']\n",
        "gif_links = [\n",
        "    \"https://i.giphy.com/media/v1.Y2lkPTc5MGI3NjExMHJ1NXdxOXF0MnE0bGw4eXlzZDQwbW14OXd6eXg1NGV6eGUwNHRvOSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/xTiTnh2PC1qEjDQUrC/giphy.gif\",\n",
        "    \"https://i.giphy.com/media/v1.Y2lkPTc5MGI3NjExZjJtczl4bTJwdzczdmJvbGdkNzNmdDlsY2c5NHR2d2o5aXFzbmx0eSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/7nUkHEdz3AMkkbGWV1/giphy.gif\",\n",
        "]\n",
        "\n",
        "last_results = pd.DataFrame()  # To store the last filtered results\n",
        "\n",
        "def is_gift_related(message):\n",
        "    return any(keyword in message.lower() for keyword in gift_keywords)\n",
        "\n",
        "def is_faq_related(message):\n",
        "    for pattern, response in faq_patterns:\n",
        "        if re.search(pattern, message.lower()):\n",
        "            return response\n",
        "    return None\n",
        "\n",
        "def show_gif():\n",
        "    print(f\"Check this out! {random.choice(gif_links)}\")\n",
        "\n",
        "def ask_gift_questions():\n",
        "    print(f\"{random.choice(fun_emojis)} Let's find the perfect gift for you! {random.choice(fun_emojis)}\")\n",
        "    recipient = input(\"üë§ Who is the gift for? (adult, child, teen): \").lower()\n",
        "    gender = input(\"üöª What is the gender of the person? (male, female, unisex): \").lower()\n",
        "    occasion = input(\"üéâ What is the occasion? (birthday, Christmas, charity, other): \").lower()\n",
        "    relationship = input(\"ü§ù What is your relationship with the person? (family, friends, colleagues, other): \").lower()\n",
        "    interest = input(\"üí° What are their interests? (sports, music, reading, etc.): \").lower()\n",
        "    budget = input(\"üí∏ What is your maximum budget? (in euros): \")\n",
        "    return recipient, gender, occasion, relationship, interest, budget\n",
        "\n",
        "def filter_gifts(recipient, gender, occasion, relationship, interest, budget):\n",
        "    global last_results\n",
        "    try:\n",
        "        budget = float(budget)\n",
        "    except ValueError:\n",
        "        print(\"‚ö†Ô∏è Invalid budget. Using the maximum budget by default.\")\n",
        "        budget = gift_df['Prix (‚Ç¨)'].max()\n",
        "\n",
        "    results = gift_df[\n",
        "        (gift_df['Tranche d\\'√Çge'].str.lower() == recipient) &\n",
        "        ((gift_df['Sexe'].str.lower() == gender) | (gift_df['Sexe'].str.lower() == 'unisexe')) &\n",
        "        (gift_df['Event'].str.lower().str.contains(occasion, na=False)) &\n",
        "        (gift_df['Scope'].str.lower().str.contains(relationship, na=False)) &\n",
        "        (gift_df['Centres d\\'Int√©r√™t'].str.contains(interest, case=False, na=False)) &\n",
        "        (gift_df['Prix (‚Ç¨)'] <= budget)\n",
        "    ]\n",
        "    last_results = results\n",
        "    return results.head(5)\n",
        "\n",
        "def recommend_gifts():\n",
        "    recipient, gender, occasion, relationship, interest, budget = ask_gift_questions()\n",
        "    results = filter_gifts(recipient, gender, occasion, relationship, interest, budget)\n",
        "    if not results.empty:\n",
        "        print(f\"{random.choice(fun_emojis)} Here are some amazing gift ideas for you! {random.choice(fun_emojis)}\")\n",
        "        show_gif()\n",
        "        time.sleep(1)\n",
        "        for idx, row in results.iterrows():\n",
        "            print(f\"üéÅ {row['Nom du Produit']}: {row['Description du Produit']} (üíµ Price: {row['Prix (‚Ç¨)']}‚Ç¨)\")\n",
        "            time.sleep(0.5)\n",
        "        ask_for_more_ideas()\n",
        "    else:\n",
        "        print(\"üòî Sorry, no gifts matched your criteria. Maybe you should try with different criteria!\")\n",
        "        show_gif()\n",
        "\n",
        "def ask_for_more_ideas():\n",
        "    more = input(\"Would you like to see more gift ideas? (yes/no): \").lower()\n",
        "    if more == 'yes':\n",
        "        show_more_gifts()\n",
        "\n",
        "def show_more_gifts():\n",
        "    global last_results\n",
        "    more_results = last_results.iloc[5:]\n",
        "    if not more_results.empty:\n",
        "        print(f\"{random.choice(fun_emojis)} Here are more gift ideas for you! {random.choice(fun_emojis)}\")\n",
        "        show_gif()\n",
        "        for idx, row in more_results.iterrows():\n",
        "            print(f\"üéÅ {row['Nom du Produit']}: {row['Description du Produit']} (üíµ Price: {row['Prix (‚Ç¨)']}‚Ç¨)\")\n",
        "            time.sleep(0.5)\n",
        "        print(\"‚ú® That's all the gift ideas matching your criteria! If nothing fits, you can refine your search. Would you like to refine your criteria? (yes/no)\")\n",
        "        refine = input().lower()\n",
        "        if refine == 'yes':\n",
        "            recommend_gifts()\n",
        "        else:\n",
        "            print(\"üí° What else can I help you with?\")\n",
        "            general_chat(input(\"You: \"))\n",
        "    else:\n",
        "        print(\"‚ú® No more gift ideas available! ‚ú®\")\n",
        "\n",
        "def general_chat(user_message):\n",
        "    faq_response = is_faq_related(user_message)\n",
        "    if faq_response:\n",
        "        print(faq_response)\n",
        "        show_gif()\n",
        "    else:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[{\"role\": \"user\", \"content\": user_message}],\n",
        "            max_tokens=150\n",
        "        )\n",
        "        print(response['choices'][0]['message']['content'].strip())\n",
        "\n",
        "def main():\n",
        "    print(f\"{random.choice(fun_emojis)} Hello! I'm your personal assistant. Ask me anything! {random.choice(fun_emojis)}\")\n",
        "    while True:\n",
        "        user_message = input(\"You: \")\n",
        "        if 'exit' in user_message.lower():\n",
        "            print(f\"üëã Goodbye! Have a fantastic day! {random.choice(fun_emojis)}\")\n",
        "            break\n",
        "        elif is_gift_related(user_message):\n",
        "            recommend_gifts()\n",
        "        else:\n",
        "            general_chat(user_message)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5CFkB70AFqg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}